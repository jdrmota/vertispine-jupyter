{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f509e545-9091-411a-9940-f6cd75261ce7",
   "metadata": {},
   "source": [
    "# vertispine 3C\n",
    "\n",
    "## Machine learning classification algorithm predicting 3 target spinal normality/abnormalities from 6 biomechanical X-ray image derived features, deployed at https://vertispine.vercel.app/\n",
    "\n",
    "### Created by Jan Drmota for BOA x Stryker Hackathon 2024\n",
    "\n",
    "This version (vertispine3C) predicts either normal, hernia or spondylolisthesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a5f97f-fd01-48bd-b733-c22d7878ebdc",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "Please select Run > Run All Cells from the top menubar. You may need to restart the kernel after installing the libraries by going to \"Kernel > Restart Kernal\" in the top menubar and then re-run all cells with \"Run > Run All Cells\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8e71cd-1deb-4066-8673-a70195d199b4",
   "metadata": {},
   "source": [
    "### Machine learning algorithm\n",
    "\n",
    "The data was examined and the k-nearest neighbors (kNN) machine learning algorithm (MLA) was selected due to the nature of the data and task.\n",
    "The task involves classification and kNN is one of the widely-used MLAs used for this task as the statistical distribution of the data is not considered. \n",
    "The distance between the data points in this case, makes kNN a relevant choice.\n",
    "Though there are down-sides to using this algorithm including slower predicive speed (as computation is deferred to prediction stage) and reduced performance in high-dimensional data spaces, I believe for the task at hand with the data size and nature it is the most appropriate choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9785130-b4a5-4456-8e40-06b0716872b1",
   "metadata": {},
   "source": [
    "### Downloading dataset\n",
    "The dataset was downloaded from [UC Irvine's Machine Learning Repository](https://archive.ics.uci.edu/dataset/212/vertebral+column) as outlined in the instructions and stored in a data folder in the root directory of the project:\n",
    "> ./data/column_3C_weka.arff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7605c55-5872-4f40-a75f-fce7960e7ee9",
   "metadata": {},
   "source": [
    "### Installing libraries\n",
    "\n",
    "Python3 and pip3 was used to create this, the following commands are run to install the necessary libraries (I was using Anaconda which comes with all these libraries already):\n",
    "\n",
    "> pip3 install numpy<br>\n",
    "> pip3 install pandas<br>\n",
    "> pip3 install scipy<br>\n",
    "> pip3 install scikit-learn<br>\n",
    "> pip3 install matplotlib<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d876c5c-f12c-415b-9651-884e780b39f2",
   "metadata": {},
   "source": [
    "Alternatively install them from the requirements.txt folder (**you may need to restart the kernel by going to \"Kernel > Restart Kernal\" in the top menubar and then re-run all cells with \"Run > Run All Cells\"**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cd7735-fb9e-49cf-800a-c25db3b7aeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#jupyter nbconvert --to script --execute --stdout vertispine3C.ipynb | python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "377c6e19-932e-4a74-b125-5672629a86cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn==1.5.1 in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (1.5.1)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (3.9.3)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (1.26.4)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (2.2.3)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (1.13.1)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn==1.5.1->-r requirements.txt (line 1)) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 2)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 2)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 2)) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 2)) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 2)) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 2)) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 2)) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 4)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 4)) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 2)) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    get_ipython()  # Check if running in a Jupyter notebook, if yes run the following command to install libraries:\n",
    "    %pip install -r requirements.txt\n",
    "except NameError:\n",
    "    # This checks if the notebook is run from the command line with nbconvert, \n",
    "    # then the modules will have to be installed with the command pip install -r requirements.txt in the command line\n",
    "    print(\"Not in IPython or Jupyter, if you get an error that libraries/modules not found then install packages with the command: pip install -r requirements.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd133f8-2fb1-47e0-a9d9-74b24bb2e58e",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "c98d2fc1-1e89-4930-96dc-76c5f134dc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from scipy.io import arff\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197b6e56-020f-4102-aeff-1aba921d6b5b",
   "metadata": {},
   "source": [
    "### Importing data from .arff file\n",
    "We read the downloaded file from the data folder with arff using SciPy's input/output module scipy.io. arff loads the data into a (data, meta) tuple. As such, we need to import only the first index ie the data into our dataframe from the pandas library. The following function ensures the file is in the default location, if not please enter where the file is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "f99687ab-497b-49be-993a-640053d823d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to load dataset from default path: ./data/column_3C_weka.arff\n",
      "Dataset loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "default_dataset_path = \"./data/column_3C_weka.arff\"\n",
    "\n",
    "def load_dataset():\n",
    "    try:\n",
    "        # Attempt to load the dataset from the default path\n",
    "        print(f\"Trying to load dataset from default path: {default_dataset_path}\")\n",
    "        arff_file = arff.loadarff(default_dataset_path)\n",
    "    except FileNotFoundError:\n",
    "        # If the default path is invalid, ask the user for an alternative path\n",
    "        user_path = input(\"Default dataset path not found. Please enter the path to your dataset: \")\n",
    "        if not os.path.exists(user_path):\n",
    "            raise FileNotFoundError(f\"Dataset not found at {user_path}. Please check the path and try again.\")\n",
    "        arff_file = arff.loadarff(user_path)\n",
    "    return arff_file\n",
    "\n",
    "# Load the dataset\n",
    "try:\n",
    "    arff_data = load_dataset()\n",
    "    df = pd.DataFrame(arff_data[0])\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "except FileNotFoundError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5055de-d73c-49e1-b578-9c0450db7065",
   "metadata": {},
   "source": [
    "### Data shape\n",
    "We first examine what the shape of the stored data is. From the UC Irvine repository we expect 310 instances and 7 variables in our imported dataframe. We confirm this below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "3b6bc4cf-bff8-4842-9e63-6470c28e0572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(310, 7)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3a151f-1465-433d-90ca-7ff71431f82b",
   "metadata": {},
   "source": [
    "### Data structure\n",
    "We can confirm the expected variables and observe the data by printing our dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "bfef89f8-7a54-4fa2-b831-5873351a2d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pelvic_incidence</th>\n",
       "      <th>pelvic_tilt</th>\n",
       "      <th>lumbar_lordosis_angle</th>\n",
       "      <th>sacral_slope</th>\n",
       "      <th>pelvic_radius</th>\n",
       "      <th>degree_spondylolisthesis</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.027817</td>\n",
       "      <td>22.552586</td>\n",
       "      <td>39.609117</td>\n",
       "      <td>40.475232</td>\n",
       "      <td>98.672917</td>\n",
       "      <td>-0.254400</td>\n",
       "      <td>b'Hernia'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.056951</td>\n",
       "      <td>10.060991</td>\n",
       "      <td>25.015378</td>\n",
       "      <td>28.995960</td>\n",
       "      <td>114.405425</td>\n",
       "      <td>4.564259</td>\n",
       "      <td>b'Hernia'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68.832021</td>\n",
       "      <td>22.218482</td>\n",
       "      <td>50.092194</td>\n",
       "      <td>46.613539</td>\n",
       "      <td>105.985135</td>\n",
       "      <td>-3.530317</td>\n",
       "      <td>b'Hernia'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69.297008</td>\n",
       "      <td>24.652878</td>\n",
       "      <td>44.311238</td>\n",
       "      <td>44.644130</td>\n",
       "      <td>101.868495</td>\n",
       "      <td>11.211523</td>\n",
       "      <td>b'Hernia'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.712859</td>\n",
       "      <td>9.652075</td>\n",
       "      <td>28.317406</td>\n",
       "      <td>40.060784</td>\n",
       "      <td>108.168725</td>\n",
       "      <td>7.918501</td>\n",
       "      <td>b'Hernia'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>47.903565</td>\n",
       "      <td>13.616688</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>34.286877</td>\n",
       "      <td>117.449062</td>\n",
       "      <td>-4.245395</td>\n",
       "      <td>b'Normal'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>53.936748</td>\n",
       "      <td>20.721496</td>\n",
       "      <td>29.220534</td>\n",
       "      <td>33.215251</td>\n",
       "      <td>114.365845</td>\n",
       "      <td>-0.421010</td>\n",
       "      <td>b'Normal'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>61.446597</td>\n",
       "      <td>22.694968</td>\n",
       "      <td>46.170347</td>\n",
       "      <td>38.751628</td>\n",
       "      <td>125.670725</td>\n",
       "      <td>-2.707880</td>\n",
       "      <td>b'Normal'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>45.252792</td>\n",
       "      <td>8.693157</td>\n",
       "      <td>41.583126</td>\n",
       "      <td>36.559635</td>\n",
       "      <td>118.545842</td>\n",
       "      <td>0.214750</td>\n",
       "      <td>b'Normal'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>33.841641</td>\n",
       "      <td>5.073991</td>\n",
       "      <td>36.641233</td>\n",
       "      <td>28.767649</td>\n",
       "      <td>123.945244</td>\n",
       "      <td>-0.199249</td>\n",
       "      <td>b'Normal'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>310 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pelvic_incidence  pelvic_tilt  lumbar_lordosis_angle  sacral_slope  \\\n",
       "0           63.027817    22.552586              39.609117     40.475232   \n",
       "1           39.056951    10.060991              25.015378     28.995960   \n",
       "2           68.832021    22.218482              50.092194     46.613539   \n",
       "3           69.297008    24.652878              44.311238     44.644130   \n",
       "4           49.712859     9.652075              28.317406     40.060784   \n",
       "..                ...          ...                    ...           ...   \n",
       "305         47.903565    13.616688              36.000000     34.286877   \n",
       "306         53.936748    20.721496              29.220534     33.215251   \n",
       "307         61.446597    22.694968              46.170347     38.751628   \n",
       "308         45.252792     8.693157              41.583126     36.559635   \n",
       "309         33.841641     5.073991              36.641233     28.767649   \n",
       "\n",
       "     pelvic_radius  degree_spondylolisthesis      class  \n",
       "0        98.672917                 -0.254400  b'Hernia'  \n",
       "1       114.405425                  4.564259  b'Hernia'  \n",
       "2       105.985135                 -3.530317  b'Hernia'  \n",
       "3       101.868495                 11.211523  b'Hernia'  \n",
       "4       108.168725                  7.918501  b'Hernia'  \n",
       "..             ...                       ...        ...  \n",
       "305     117.449062                 -4.245395  b'Normal'  \n",
       "306     114.365845                 -0.421010  b'Normal'  \n",
       "307     125.670725                 -2.707880  b'Normal'  \n",
       "308     118.545842                  0.214750  b'Normal'  \n",
       "309     123.945244                 -0.199249  b'Normal'  \n",
       "\n",
       "[310 rows x 7 columns]"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5636a3-4ab5-4930-97e1-073710f031db",
   "metadata": {},
   "source": [
    "### Missing data\n",
    "We need to confirm there is no missing data in our dataframe by running isna(), which converts our dataframe into Booleans with any data missing indicated as True (i.e. 1) and no data missing as False (i.e. 0) and then summing the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "b454288a-bdc9-447a-b9d6-97d28d36cf68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pelvic_incidence            0\n",
      "pelvic_tilt                 0\n",
      "lumbar_lordosis_angle       0\n",
      "sacral_slope                0\n",
      "pelvic_radius               0\n",
      "degree_spondylolisthesis    0\n",
      "class                       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69208ef5-b91f-44ab-a3f7-3116ca0a0d67",
   "metadata": {},
   "source": [
    "There is no missing data that needs to be inputted and we can continue with building our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3978bf61-615a-4fc7-b184-62288740fd12",
   "metadata": {},
   "source": [
    "### Assigning MLA variables\n",
    "We assign the variable X our independent data inputs (all except the last column \"class\") and the variable y our dependent targets (column \"class\") from our dataframe.\n",
    "The sklearn module requires the targets are in string format but in our dataframe they are currently objects, as such a type conversion was made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "cdebdc37-11d8-4bdd-aa91-6ecb4107f56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"class\"])\n",
    "df[\"class\"] = df[\"class\"].astype(\"string\")\n",
    "y = df[\"class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd44e994-c3a2-48f9-a772-ec5f77283e1a",
   "metadata": {},
   "source": [
    "### Scaling data\n",
    "For the kNN selection (as it is distance-based), scaling data (standardisation of data) is important to ensure the variation in scale between the independent features does not affect our results. We use the Scikit-learn's StandardScaler preprocessing library for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "a1762c08-6605-4566-9d65-0d032ef03db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd70ac8-e196-49e7-8146-6c7c0fc917f3",
   "metadata": {},
   "source": [
    "### Assigning train/test split\n",
    "Next we want to prepare our training and testing data subsets, storing our scaled X and y variables into their respective subsets. The conventional 80/20 training/testing split and the conventional 42 seed for reproducible randomness are used, we also want to ensure the target class is distributed in the same way in the training and testing subsets hence why it is stratified with y (our target \"class\"). The train_test_split from the scikit-learn library is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "82897ea9-70a4-4444-8751-ef7bb46e43ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X_scaled, y, test_size=0.20, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ded7d58-70f9-4474-b83a-a1f25fd730bc",
   "metadata": {},
   "source": [
    "### Cross validation parameters\n",
    "Here we create an object with possible parameter values for our kNN we will want our cross-validation to test. We will trial between 2 and 20 number of neighbours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "963c887c-7a66-4004-8d28-5e2c048d4943",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter = {\n",
    "    'n_neighbors': np.arange(2, 21, 1),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski'],\n",
    "    'algorithm': ['auto']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a202d88-9938-439b-971b-99598cfee4a6",
   "metadata": {},
   "source": [
    "### Stratified K-Fold cross validation\n",
    "We are using a stratified K-fold crossvalidation with Grid search rather than only a conventional train/test split. A normal train/test split may not be as representative as it is only one run and may cause overfitting/underfitting. Though we may get a lower accuracy from this cross-validation we can be assured this is a more reliable estimate of the performance as we run several tests on our data rather than just one, in our case we are using a k-value of 10. All the data is used for the testing, rather than just the 80% that would be used in a train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "dd58706f-f067-43ef-949c-97fe34b36c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3c902f-e840-43bb-b651-aae149a33d6c",
   "metadata": {},
   "source": [
    "### Hyperparametric tuning with grid search\n",
    "We then validate our kNN algorithms on the training set to see which one yields the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "c0e7c074-d36a-4641-bfb3-da7d8070ea91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 114 candidates, totalling 1140 fits\n",
      "Best Parameters: {'algorithm': 'auto', 'metric': 'euclidean', 'n_neighbors': 13, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "knn_cv = GridSearchCV(knn, param_grid=parameter, cv=skf, verbose=1)\n",
    "knn_cv.fit(X_train_scaled, y_train)\n",
    "print(\"Best Parameters:\", knn_cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321348ab-fc1c-4dbc-ba04-9972d6c7f77d",
   "metadata": {},
   "source": [
    "### Evaluate best kNN on test set\n",
    "The final accuracy is from the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "c3144e0b-5f96-4cde-91fe-422861ad5451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy on Test Set: 79.03%\n"
     ]
    }
   ],
   "source": [
    "best_knn = knn_cv.best_estimator_\n",
    "best_knn.fit(X_train_scaled, y_train)\n",
    "y_pred = best_knn.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "print(\"Final Accuracy on Test Set: {:.2f}%\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faea74a-9d2e-476a-9448-56a039d1f15d",
   "metadata": {},
   "source": [
    "### Creating a pipeline for our best kNN\n",
    "Last, we can create a pipeline saving our best kNN and the scaler that we can then save and use for real-life data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "6647d52d-55d9-4021-aed0-ba7084452780",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('scaler', scaler),\n",
    "    ('knn', best_knn)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36b144d-3f09-4604-be3f-7fbcd6c5fbdb",
   "metadata": {},
   "source": [
    "### Saving our pipeline into a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "a078b882-a4b9-4614-8b81-4d555b03b1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vertispine3CMLPipeline.pkl']"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(pipeline, 'vertispine3CMLPipeline.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b02d24c-cae8-4f5e-b48b-552dc268f2cc",
   "metadata": {},
   "source": [
    "### Loading our saved pipeline file with best kNN and using it on real-world data\n",
    "Here we load the saved pipeline from the file and run a test on 4 selected datasets (as if it were data from real-life). These should be Normal, Normal, Hernia and Spondylolisthesis for illustrative purposes only. The pipeline scales the data and classifies using the best_knn we saved.\n",
    "This is deployed in the [vertispine web-app at https://vertispine.vercel.app/](https://vertispine.vercel.app/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "cc4652c9-a8f3-4a77-9582-f935fd4f0bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Normal' 'Normal' 'Hernia' 'Spondylolisthesis']\n"
     ]
    }
   ],
   "source": [
    "loaded_pipeline = joblib.load('vertispine3CMLPipeline.pkl')\n",
    "\n",
    "d_two = {'pelvic_incidence': [45.252792, 33.841641, 74.433593, 70.952728], 'pelvic_tilt': [8.693157, 5.073991, 41.557331, 20.159931], 'lumbar_lordosis_angle': [41.583126, 36.641233, 27.700000, 62.859109], 'sacral_slope': [36.559635, 28.767649, 32.876262, 50.792797], 'pelvic_radius': [118.545842, 123.945244, 107.949304, 116.177932], 'degree_spondylolisthesis': [0.214750, -0.199249, 5.000089, 32.522331]}\n",
    "\n",
    "df_two = pd.DataFrame(data=d_two)\n",
    "\n",
    "two_prediction = loaded_pipeline.predict(df_two)\n",
    "\n",
    "print(two_prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
